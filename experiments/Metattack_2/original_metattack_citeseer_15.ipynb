{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0ca698-ae54-4c46-ad6c-bd77183960cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gcn import GCN\n",
    "from utils import load_data, preprocess, normalize_adj_tensor, accuracy, get_train_val_test\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from metattack import MetaApprox, Metattack\n",
    "import seaborn as sns\n",
    "from deeprobust.graph.data import Dataset\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321d9d03-d1d4-49bf-90d9-ccb00ec83626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed parameters for Cora dataset\n",
    "torch.cuda.empty_cache()\n",
    "seed = 15\n",
    "epochs = 200\n",
    "lr = 0.01\n",
    "hidden = 64  # Changed from 16 to 64 as requested\n",
    "dataset = 'citeseer'\n",
    "model_variant = 'Meta-Self'  # Options: 'A-Meta-Self', 'Meta-Self'\n",
    "ptb_rates = [0.13]  # Multiple perturbation rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7961f18b-278c-42c1-a8c2-b2e8fae96133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading citeseer dataset...\n",
      "reading citeseer...\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device != 'cpu':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Load Cora dataset\n",
    "adj, features, labels = load_data(dataset=dataset)\n",
    "nclass = max(labels) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8981d78-7f10-4c80-a843-e0a30c90c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "val_size = 0.1\n",
    "test_size = 0.8\n",
    "train_size = 1 - test_size - val_size\n",
    "idx = np.arange(adj.shape[0])\n",
    "idx_train, idx_val, idx_test = get_train_val_test(idx, train_size, val_size, test_size, stratify=labels)\n",
    "idx_unlabeled = np.union1d(idx_val, idx_test)\n",
    "\n",
    "# Preprocess without normalizing adjacency yet\n",
    "adj, features, labels = preprocess(adj, features, labels, preprocess_adj=False)\n",
    "\n",
    "# Move data to device\n",
    "if device != 'cpu':\n",
    "    adj = adj.to(device)\n",
    "    features = features.to(device)\n",
    "    labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce1c9e2-3ddd-470d-8ece-b9186ed7f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gcn(adj):\n",
    "    ''' Train GCN on the given adjacency matrix '''\n",
    "    # Normalize adjacency matrix for GCN\n",
    "    norm_adj = normalize_adj_tensor(adj)\n",
    "    \n",
    "    # Initialize GCN model - the provided GCN is already 2-layer\n",
    "    # We just need to set the hidden dimension to 64\n",
    "    gcn = GCN(nfeat=features.shape[1],\n",
    "              nhid=hidden,\n",
    "              nclass=labels.max().item() + 1,\n",
    "              dropout=0.5)\n",
    "    \n",
    "    if device != 'cpu':\n",
    "        gcn = gcn.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(gcn.parameters(),\n",
    "                           lr=lr, weight_decay=5e-4)\n",
    "    \n",
    "    # Train GCN\n",
    "    gcn.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = gcn(features, norm_adj)\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192f145d-4e74-4cf6-a095-5da1557496e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gcn, adj, idx):\n",
    "    ''' Evaluate GCN on the given adjacency matrix and index '''\n",
    "    # Normalize adjacency matrix for evaluation\n",
    "    norm_adj = normalize_adj_tensor(adj)\n",
    "    \n",
    "    gcn.eval()\n",
    "    with torch.no_grad():\n",
    "        output = gcn(features, norm_adj)\n",
    "        loss = F.nll_loss(output[idx], labels[idx])\n",
    "        acc = accuracy(output[idx], labels[idx])\n",
    "    \n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e51acc-9083-4cf2-9055-db97b5247203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attack():\n",
    "    results = {}\n",
    "    \n",
    "    print('=== Training GCN on original(clean) graph ===')\n",
    "    # First, train the GCN on the clean graph\n",
    "    trained_gcn = train_gcn(adj)\n",
    "    \n",
    "    # Set up attack model parameters\n",
    "    if 'Self' in model_variant:\n",
    "        lambda_ = 0\n",
    "    if 'Train' in model_variant:\n",
    "        lambda_ = 1\n",
    "    if 'Both' in model_variant:\n",
    "        lambda_ = 0.5\n",
    "    \n",
    "    # Configure attack model\n",
    "    if 'A' in model_variant:\n",
    "        model_class = MetaApprox\n",
    "    else:\n",
    "        model_class = Metattack\n",
    "    \n",
    "    # Evaluate across different perturbation rates\n",
    "    for ptb_rate in ptb_rates:\n",
    "        print(f'\\n=== Testing perturbation rate: {ptb_rate*100:.1f}% ===')\n",
    "        perturbations = int(ptb_rate * (adj.sum()//2))\n",
    "        \n",
    "        print('=== Setting up attack model ===')\n",
    "        model = model_class(nfeat=features.shape[1], hidden_sizes=[hidden],\n",
    "                        nnodes=adj.shape[0], nclass=nclass, dropout=0.5,\n",
    "                        train_iters=0, attack_features=False, lambda_=lambda_, device=device)\n",
    "        \n",
    "        if device != 'cpu':\n",
    "            model = model.to(device)\n",
    "            \n",
    "        # Generate adversarial adjacency matrix focusing on test nodes\n",
    "        print(f'=== Perturbing graph with {perturbations} edge modifications ===')\n",
    "        \n",
    "        modified_adj = model(features, adj, labels, idx_train, idx_test, perturbations, ll_constraint=False)\n",
    "        modified_adj = modified_adj.detach()\n",
    "        \n",
    "        runs = 3  # Reduced from 10 to 3 for quicker execution\n",
    "        clean_acc = []\n",
    "        attacked_acc = []\n",
    "        \n",
    "        print('=== Evaluating GCN performance ===')\n",
    "        # Test the already trained GCN on both clean and perturbed graph\n",
    "        for i in range(runs):\n",
    "            # Reset the GCN for each run\n",
    "            trained_gcn = train_gcn(adj)\n",
    "            \n",
    "            # Evaluate on clean test data\n",
    "            clean_acc.append(evaluate(trained_gcn, adj, idx_test))\n",
    "            \n",
    "            # Evaluate on perturbed test data (evasion)\n",
    "            attacked_acc.append(evaluate(trained_gcn, modified_adj, idx_test))\n",
    "            \n",
    "            print(f\"Run {i+1}/{runs}: Clean acc = {clean_acc[-1]:.4f}, Attacked acc = {attacked_acc[-1]:.4f}\")\n",
    "        \n",
    "        # Calculate effectiveness metrics\n",
    "        clean_mean = np.mean(clean_acc)\n",
    "        clean_std = np.std(clean_acc)\n",
    "        attack_mean = np.mean(attacked_acc)\n",
    "        attack_std = np.std(attacked_acc)\n",
    "        acc_drop = clean_mean - attack_mean\n",
    "        relative_drop = (acc_drop / clean_mean) * 100\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\n=== Attack Effectiveness Summary (Perturbation rate: {ptb_rate*100:.1f}%) ===\")\n",
    "        print(f\"Clean accuracy: {clean_mean:.4f} ± {clean_std:.4f}\")\n",
    "        print(f\"Attacked accuracy: {attack_mean:.4f} ± {attack_std:.4f}\")\n",
    "        print(f\"Absolute accuracy drop: {acc_drop:.4f}\")\n",
    "        print(f\"Relative accuracy drop: {relative_drop:.2f}%\")\n",
    "        print(f\"Effectiveness ratio: {acc_drop/ptb_rate:.4f} (drop per perturbation unit)\")\n",
    "        \n",
    "        # Assessment\n",
    "        if acc_drop > 0.10:\n",
    "            print(\"Attack assessment: Highly effective\")\n",
    "        elif acc_drop > 0.05:\n",
    "            print(\"Attack assessment: Moderately effective\")\n",
    "        elif acc_drop > 0.02:\n",
    "            print(\"Attack assessment: Slightly effective\")\n",
    "        else:\n",
    "            print(\"Attack assessment: Minimally effective\")\n",
    "        \n",
    "        # Store results\n",
    "        results[ptb_rate] = {\n",
    "            'modified_adj': modified_adj,\n",
    "            'clean_acc': clean_acc,\n",
    "            'attacked_acc': attacked_acc,\n",
    "            'accuracy_drop': acc_drop,\n",
    "            'relative_drop': relative_drop,\n",
    "            'effectiveness_ratio': acc_drop/ptb_rate\n",
    "        }\n",
    "        \n",
    "        # Free up memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Add overall results\n",
    "    results['clean_adj'] = adj\n",
    "    \n",
    "    # Create and save comparative visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    ptb_values = list(ptb_rates)\n",
    "    acc_drops = [results[ptb]['accuracy_drop'] for ptb in ptb_rates]\n",
    "    rel_drops = [results[ptb]['relative_drop'] for ptb in ptb_rates]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(ptb_values, acc_drops, 'o-', linewidth=2)\n",
    "    plt.xlabel('Perturbation Rate')\n",
    "    plt.ylabel('Absolute Accuracy Drop')\n",
    "    plt.title('Impact of Perturbation Rate on Accuracy Drop')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(ptb_values, rel_drops, 'o-', linewidth=2, color='orange')\n",
    "    plt.xlabel('Perturbation Rate')\n",
    "    plt.ylabel('Relative Accuracy Drop (%)')\n",
    "    plt.title('Impact of Perturbation Rate on Relative Accuracy Drop')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('perturbation_impact.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7d0656-91de-4335-ac1c-aee2abcda42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    \"\"\"Clean GPU memory and garbage collect\"\"\"\n",
    "    if device != 'cpu':\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32897a0-ada7-46c1-b199-118f2c207bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training GCN on original(clean) graph ===\n",
      "\n",
      "=== Testing perturbation rate: 13.0% ===\n",
      "=== Setting up attack model ===\n",
      "=== Perturbing graph with 476 edge modifications ===\n",
      "=== training surrogate model to predict unlabled data for self-training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   1%|▌                                                                | 4/476 [00:00<00:14, 33.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8471766710281372\n",
      "GCN acc on unlabled data: 0.12203791469194314\n",
      "attack loss: 1.8366998434066772\n",
      "GCN loss on unlabled data: 1.7757670879364014\n",
      "GCN acc on unlabled data: 0.21504739336492892\n",
      "attack loss: 1.7775812149047852\n",
      "GCN loss on unlabled data: 1.7863550186157227\n",
      "GCN acc on unlabled data: 0.21504739336492892\n",
      "attack loss: 1.7866251468658447\n",
      "GCN loss on unlabled data: 1.892317771911621\n",
      "GCN acc on unlabled data: 0.1765402843601896\n",
      "attack loss: 1.9162280559539795\n",
      "GCN loss on unlabled data: 1.9482496976852417\n",
      "GCN acc on unlabled data: 0.1575829383886256\n",
      "attack loss: 1.9510427713394165\n",
      "GCN loss on unlabled data: 1.8410935401916504\n",
      "GCN acc on unlabled data: 0.19609004739336494\n",
      "attack loss: 1.8667527437210083\n",
      "GCN loss on unlabled data: 1.853586196899414\n",
      "GCN acc on unlabled data: 0.14454976303317538\n",
      "attack loss: 1.8671443462371826\n",
      "GCN loss on unlabled data: 1.8589560985565186\n",
      "GCN acc on unlabled data: 0.15639810426540285\n",
      "attack loss: 1.8896580934524536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   3%|█▉                                                              | 14/476 [00:00<00:11, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8866548538208008\n",
      "GCN acc on unlabled data: 0.14277251184834125\n",
      "attack loss: 1.8955787420272827\n",
      "GCN loss on unlabled data: 1.8121960163116455\n",
      "GCN acc on unlabled data: 0.20142180094786732\n",
      "attack loss: 1.7935444116592407\n",
      "GCN loss on unlabled data: 1.936407208442688\n",
      "GCN acc on unlabled data: 0.11789099526066352\n",
      "attack loss: 1.949977159500122\n",
      "GCN loss on unlabled data: 1.7952238321304321\n",
      "GCN acc on unlabled data: 0.2061611374407583\n",
      "attack loss: 1.7744115591049194\n",
      "GCN loss on unlabled data: 1.913456916809082\n",
      "GCN acc on unlabled data: 0.1279620853080569\n",
      "attack loss: 1.9282749891281128\n",
      "GCN loss on unlabled data: 1.9148504734039307\n",
      "GCN acc on unlabled data: 0.11848341232227488\n",
      "attack loss: 1.9036039113998413\n",
      "GCN loss on unlabled data: 1.8709715604782104\n",
      "GCN acc on unlabled data: 0.20379146919431282\n",
      "attack loss: 1.83245050907135\n",
      "GCN loss on unlabled data: 1.8870294094085693\n",
      "GCN acc on unlabled data: 0.19135071090047395\n",
      "attack loss: 1.8956533670425415\n",
      "GCN loss on unlabled data: 1.8997844457626343\n",
      "GCN acc on unlabled data: 0.12085308056872039\n",
      "attack loss: 1.9162602424621582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   5%|███▏                                                            | 24/476 [00:00<00:10, 43.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.756677269935608\n",
      "GCN acc on unlabled data: 0.2511848341232228\n",
      "attack loss: 1.757948875427246\n",
      "GCN loss on unlabled data: 1.8764750957489014\n",
      "GCN acc on unlabled data: 0.12440758293838863\n",
      "attack loss: 1.8763161897659302\n",
      "GCN loss on unlabled data: 1.8468490839004517\n",
      "GCN acc on unlabled data: 0.1575829383886256\n",
      "attack loss: 1.8397094011306763\n",
      "GCN loss on unlabled data: 1.8556787967681885\n",
      "GCN acc on unlabled data: 0.16528436018957346\n",
      "attack loss: 1.863849401473999\n",
      "GCN loss on unlabled data: 1.8282607793807983\n",
      "GCN acc on unlabled data: 0.19549763033175357\n",
      "attack loss: 1.7968158721923828\n",
      "GCN loss on unlabled data: 1.7930859327316284\n",
      "GCN acc on unlabled data: 0.24466824644549764\n",
      "attack loss: 1.7990057468414307\n",
      "GCN loss on unlabled data: 1.9186240434646606\n",
      "GCN acc on unlabled data: 0.11848341232227488\n",
      "attack loss: 1.9308252334594727\n",
      "GCN loss on unlabled data: 1.8247673511505127\n",
      "GCN acc on unlabled data: 0.20675355450236968\n",
      "attack loss: 1.81878662109375\n",
      "GCN loss on unlabled data: 1.846765398979187\n",
      "GCN acc on unlabled data: 0.16587677725118485\n",
      "attack loss: 1.8412895202636719\n",
      "GCN loss on unlabled data: 1.8544011116027832\n",
      "GCN acc on unlabled data: 0.18483412322274884\n",
      "attack loss: 1.8413562774658203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   7%|████▌                                                           | 34/476 [00:00<00:09, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8251756429672241\n",
      "GCN acc on unlabled data: 0.18009478672985785\n",
      "attack loss: 1.8366419076919556\n",
      "GCN loss on unlabled data: 1.9622302055358887\n",
      "GCN acc on unlabled data: 0.08293838862559243\n",
      "attack loss: 1.966123342514038\n",
      "GCN loss on unlabled data: 1.8037930727005005\n",
      "GCN acc on unlabled data: 0.21741706161137442\n",
      "attack loss: 1.770782709121704\n",
      "GCN loss on unlabled data: 1.850417971611023\n",
      "GCN acc on unlabled data: 0.1949052132701422\n",
      "attack loss: 1.839905023574829\n",
      "GCN loss on unlabled data: 1.906314492225647\n",
      "GCN acc on unlabled data: 0.12322274881516589\n",
      "attack loss: 1.9095295667648315\n",
      "GCN loss on unlabled data: 1.9196242094039917\n",
      "GCN acc on unlabled data: 0.11492890995260664\n",
      "attack loss: 1.910885214805603\n",
      "GCN loss on unlabled data: 1.890047311782837\n",
      "GCN acc on unlabled data: 0.14099526066350712\n",
      "attack loss: 1.8911423683166504\n",
      "GCN loss on unlabled data: 1.8205432891845703\n",
      "GCN acc on unlabled data: 0.16824644549763035\n",
      "attack loss: 1.8407336473464966\n",
      "GCN loss on unlabled data: 1.8771716356277466\n",
      "GCN acc on unlabled data: 0.1623222748815166\n",
      "attack loss: 1.8804529905319214\n",
      "GCN loss on unlabled data: 1.8901160955429077\n",
      "GCN acc on unlabled data: 0.15284360189573462\n",
      "attack loss: 1.9127413034439087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:   9%|█████▉                                                          | 44/476 [00:01<00:09, 46.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8451027870178223\n",
      "GCN acc on unlabled data: 0.16409952606635073\n",
      "attack loss: 1.8311861753463745\n",
      "GCN loss on unlabled data: 1.8368821144104004\n",
      "GCN acc on unlabled data: 0.18009478672985785\n",
      "attack loss: 1.8450247049331665\n",
      "GCN loss on unlabled data: 1.8065910339355469\n",
      "GCN acc on unlabled data: 0.19075829383886259\n",
      "attack loss: 1.779954195022583\n",
      "GCN loss on unlabled data: 1.8891863822937012\n",
      "GCN acc on unlabled data: 0.1415876777251185\n",
      "attack loss: 1.8777626752853394\n",
      "GCN loss on unlabled data: 1.8408100605010986\n",
      "GCN acc on unlabled data: 0.16587677725118485\n",
      "attack loss: 1.8395129442214966\n",
      "GCN loss on unlabled data: 1.7958976030349731\n",
      "GCN acc on unlabled data: 0.18661137440758296\n",
      "attack loss: 1.8009614944458008\n",
      "GCN loss on unlabled data: 1.7910469770431519\n",
      "GCN acc on unlabled data: 0.22393364928909953\n",
      "attack loss: 1.7865010499954224\n",
      "GCN loss on unlabled data: 1.8642528057098389\n",
      "GCN acc on unlabled data: 0.13625592417061613\n",
      "attack loss: 1.8713757991790771\n",
      "GCN loss on unlabled data: 1.875472903251648\n",
      "GCN acc on unlabled data: 0.148696682464455\n",
      "attack loss: 1.8853975534439087\n",
      "GCN loss on unlabled data: 1.8407742977142334\n",
      "GCN acc on unlabled data: 0.16824644549763035\n",
      "attack loss: 1.8352593183517456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  11%|███████▎                                                        | 54/476 [00:01<00:08, 46.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8609329462051392\n",
      "GCN acc on unlabled data: 0.14691943127962087\n",
      "attack loss: 1.8668394088745117\n",
      "GCN loss on unlabled data: 1.8056703805923462\n",
      "GCN acc on unlabled data: 0.1712085308056872\n",
      "attack loss: 1.7848389148712158\n",
      "GCN loss on unlabled data: 1.8488428592681885\n",
      "GCN acc on unlabled data: 0.2061611374407583\n",
      "attack loss: 1.8401169776916504\n",
      "GCN loss on unlabled data: 1.8112133741378784\n",
      "GCN acc on unlabled data: 0.17002369668246448\n",
      "attack loss: 1.800360918045044\n",
      "GCN loss on unlabled data: 1.81243896484375\n",
      "GCN acc on unlabled data: 0.18601895734597157\n",
      "attack loss: 1.8195551633834839\n",
      "GCN loss on unlabled data: 1.865751028060913\n",
      "GCN acc on unlabled data: 0.13566350710900474\n",
      "attack loss: 1.8525266647338867\n",
      "GCN loss on unlabled data: 1.8270597457885742\n",
      "GCN acc on unlabled data: 0.15936018957345974\n",
      "attack loss: 1.84345543384552\n",
      "GCN loss on unlabled data: 1.8503167629241943\n",
      "GCN acc on unlabled data: 0.13744075829383887\n",
      "attack loss: 1.8733326196670532\n",
      "GCN loss on unlabled data: 1.8722715377807617\n",
      "GCN acc on unlabled data: 0.15580568720379148\n",
      "attack loss: 1.8615554571151733\n",
      "GCN loss on unlabled data: 1.752785086631775\n",
      "GCN acc on unlabled data: 0.2434834123222749\n",
      "attack loss: 1.756190538406372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  13%|████████▌                                                       | 64/476 [00:01<00:08, 47.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.7901629209518433\n",
      "GCN acc on unlabled data: 0.18957345971563982\n",
      "attack loss: 1.771983027458191\n",
      "GCN loss on unlabled data: 1.7645072937011719\n",
      "GCN acc on unlabled data: 0.25947867298578203\n",
      "attack loss: 1.7499700784683228\n",
      "GCN loss on unlabled data: 1.853928804397583\n",
      "GCN acc on unlabled data: 0.17535545023696683\n",
      "attack loss: 1.8457555770874023\n",
      "GCN loss on unlabled data: 1.9255545139312744\n",
      "GCN acc on unlabled data: 0.10722748815165878\n",
      "attack loss: 1.9485440254211426\n",
      "GCN loss on unlabled data: 1.8271421194076538\n",
      "GCN acc on unlabled data: 0.18601895734597157\n",
      "attack loss: 1.8201438188552856\n",
      "GCN loss on unlabled data: 1.8706992864608765\n",
      "GCN acc on unlabled data: 0.17298578199052134\n",
      "attack loss: 1.8866809606552124\n",
      "GCN loss on unlabled data: 1.880849838256836\n",
      "GCN acc on unlabled data: 0.15639810426540285\n",
      "attack loss: 1.8723613023757935\n",
      "GCN loss on unlabled data: 1.862335443496704\n",
      "GCN acc on unlabled data: 0.14277251184834125\n",
      "attack loss: 1.8710997104644775\n",
      "GCN loss on unlabled data: 1.8609508275985718\n",
      "GCN acc on unlabled data: 0.14040284360189575\n",
      "attack loss: 1.8643261194229126\n",
      "GCN loss on unlabled data: 1.8224996328353882\n",
      "GCN acc on unlabled data: 0.19135071090047395\n",
      "attack loss: 1.8167880773544312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  16%|█████████▉                                                      | 74/476 [00:01<00:08, 47.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8977383375167847\n",
      "GCN acc on unlabled data: 0.13388625592417064\n",
      "attack loss: 1.9085122346878052\n",
      "GCN loss on unlabled data: 1.8387125730514526\n",
      "GCN acc on unlabled data: 0.1718009478672986\n",
      "attack loss: 1.8397471904754639\n",
      "GCN loss on unlabled data: 1.8209227323532104\n",
      "GCN acc on unlabled data: 0.2221563981042654\n",
      "attack loss: 1.7992866039276123\n",
      "GCN loss on unlabled data: 1.914428949356079\n",
      "GCN acc on unlabled data: 0.12618483412322276\n",
      "attack loss: 1.9162181615829468\n",
      "GCN loss on unlabled data: 1.8869675397872925\n",
      "GCN acc on unlabled data: 0.14099526066350712\n",
      "attack loss: 1.8727422952651978\n",
      "GCN loss on unlabled data: 1.830829381942749\n",
      "GCN acc on unlabled data: 0.17002369668246448\n",
      "attack loss: 1.820177674293518\n",
      "GCN loss on unlabled data: 1.8308857679367065\n",
      "GCN acc on unlabled data: 0.19549763033175357\n",
      "attack loss: 1.8351519107818604\n",
      "GCN loss on unlabled data: 1.874547004699707\n",
      "GCN acc on unlabled data: 0.16054502369668247\n",
      "attack loss: 1.8754894733428955\n",
      "GCN loss on unlabled data: 1.837916612625122\n",
      "GCN acc on unlabled data: 0.15817535545023698\n",
      "attack loss: 1.832284927368164\n",
      "GCN loss on unlabled data: 1.8434737920761108\n",
      "GCN acc on unlabled data: 0.15639810426540285\n",
      "attack loss: 1.865402102470398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perturbing graph:  17%|███████████                                                     | 82/476 [00:01<00:08, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN loss on unlabled data: 1.8546751737594604\n",
      "GCN acc on unlabled data: 0.19549763033175357\n",
      "attack loss: 1.842084527015686\n",
      "GCN loss on unlabled data: 1.8737459182739258\n",
      "GCN acc on unlabled data: 0.14691943127962087\n",
      "attack loss: 1.8911879062652588\n",
      "GCN loss on unlabled data: 1.845984697341919\n",
      "GCN acc on unlabled data: 0.14218009478672988\n",
      "attack loss: 1.8457603454589844\n",
      "GCN loss on unlabled data: 1.7955960035324097\n",
      "GCN acc on unlabled data: 0.18720379146919433\n",
      "attack loss: 1.7817816734313965\n",
      "GCN loss on unlabled data: 1.8770570755004883\n",
      "GCN acc on unlabled data: 0.13092417061611375\n",
      "attack loss: 1.8805170059204102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 31.74 GiB total capacity; 4.40 GiB already allocated; 7.12 MiB free; 4.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m----> 3\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Print comparative summary\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Comparative Analysis ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mrun_attack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Generate adversarial adjacency matrix focusing on test nodes\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=== Perturbing graph with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperturbations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edge modifications ===\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m modified_adj \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mll_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m modified_adj \u001b[38;5;241m=\u001b[39m modified_adj\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     41\u001b[0m runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Reduced from 10 to 3 for quicker execution\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ersp_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ERSP/2-phase-attack/experiments/Metattack_2/metattack.py:235\u001b[0m, in \u001b[0;36mMetattack.forward\u001b[0;34m(self, features, ori_adj, labels, idx_train, idx_unlabeled, perturbations, ll_constraint, ll_cutoff)\u001b[0m\n\u001b[1;32m    232\u001b[0m adj_changes_symm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(adj_changes_square \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(adj_changes_square, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    233\u001b[0m modified_adj \u001b[38;5;241m=\u001b[39m adj_changes_symm \u001b[38;5;241m+\u001b[39m ori_adj\n\u001b[0;32m--> 235\u001b[0m adj_norm \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_adj_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_adj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#adj_norm = utils.normalize_adj_tensor(modified_adj.cpu()).to(device)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_train(features, adj_norm, idx_train, idx_unlabeled, labels)\n",
      "File \u001b[0;32m~/ERSP/2-phase-attack/experiments/Metattack_2/utils.py:152\u001b[0m, in \u001b[0;36mnormalize_adj_tensor\u001b[0;34m(adj, sparse)\u001b[0m\n\u001b[1;32m    150\u001b[0m     r_mat_inv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(r_inv)\n\u001b[1;32m    151\u001b[0m     mx \u001b[38;5;241m=\u001b[39m r_mat_inv \u001b[38;5;241m@\u001b[39m mx\n\u001b[0;32m--> 152\u001b[0m     mx \u001b[38;5;241m=\u001b[39m \u001b[43mmx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr_mat_inv\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mx\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 31.74 GiB total capacity; 4.40 GiB already allocated; 7.12 MiB free; 4.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.cuda.empty_cache()\n",
    "    results = run_attack()\n",
    "    \n",
    "    # Print comparative summary\n",
    "    print(\"\\n=== Comparative Analysis ===\")\n",
    "    print(\"Perturbation Rate | Accuracy Drop | Relative Drop | Effectiveness Ratio\")\n",
    "    print(\"-\" * 65)\n",
    "    for ptb_rate in ptb_rates:\n",
    "        print(f\"{ptb_rate*100:15.1f}% | {results[ptb_rate]['accuracy_drop']:12.4f} | {results[ptb_rate]['relative_drop']:12.2f}% | {results[ptb_rate]['effectiveness_ratio']:18.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e082f52-5d05-4e54-b3c1-797966e74402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
